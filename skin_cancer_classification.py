# -*- coding: utf-8 -*-
"""Copy of Skin_Cancer_Classification_Train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cu-msqkD1eAAKSbnNM6qQy5wYuUio8Lt
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass
import tensorflow as tf

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My\ Drive

import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
import time
from PIL import Image
from keras.preprocessing import image

import tensorflow as tf
import tensorflow as ktf
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.layers import Dense, Conv2D, Flatten,GlobalMaxPooling2D, Dropout, MaxPooling2D,GlobalAveragePooling2D,BatchNormalization,concatenate,Input,Lambda
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.applications import InceptionV3
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import pandas as pd
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.callbacks import ModelCheckpoint
import os
import json
import glob
from tensorflow.keras.models import load_model
from tensorflow.keras.applications import ResNet50

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Adjust the paths to point to your local directories in Google Drive
train_dir = '/content/drive/My Drive/train/train'
test_dir = '/content/drive/My Drive/test/test'

train_datagen = ImageDataGenerator(rescale=1./255,
                                    shear_range=0.2,
                                    zoom_range=0.2,
                                    horizontal_flip=True,
                                    rotation_range=60,
                                    brightness_range=(0.5, 1.5))

test_datagen = ImageDataGenerator(rescale=1./255)

training_set = train_datagen.flow_from_directory(train_dir,
                                                 target_size=(256, 256),
                                                 batch_size=32,
                                                 class_mode='binary')

test_set = test_datagen.flow_from_directory(test_dir,
                                             target_size=(256, 256),
                                             batch_size=32,
                                             class_mode='binary')

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale=1/255,validation_split=0.1, zoom_range=(0.5,1.5), rotation_range=60, brightness_range=(0.5,1.5))
train_generator = train_datagen.flow_from_directory(
        '/content/drive/My Drive/train/train',
        target_size=(256, 256),
        batch_size=128,
        class_mode='binary',
        subset='training')

validation_generator  = train_datagen.flow_from_directory(
        '/content/drive/My Drive/val/val',
        target_size=(256, 256),
        batch_size=128,
        class_mode='binary',
        subset='validation')

import tensorflow as tf

# Load the pre-trained InceptionV3 model without the top classification layer
inception = tf.keras.applications.inception_v3.InceptionV3(include_top=False, input_shape=(256, 256, 3), weights='imagenet')

# Choose a layer from the InceptionV3 model to build the custom classifier on top
layer = inception.get_layer('mixed7')
w
# Add custom classification layers on top of the InceptionV3 base
x = tf.keras.layers.Flatten()(layer.output)
x = tf.keras.layers.Dense(units=1024, activation='relu')(x)
x = tf.keras.layers.Dense(units=512, activation='relu')(x)
x = tf.keras.layers.Dense(1)(x)
out = tf.keras.layers.Activation(activation='sigmoid')(x)

# Create the model by combining the InceptionV3 base with the custom layers
model = tf.keras.Model(inputs=inception.input, outputs=out)

# Compile the model with the correct learning rate argument
model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Display model summary
model.summary()

batch_size=32
model_info=model.fit(training_set,
steps_per_epoch = 2307//batch_size,
epochs = 60,
validation_data = test_set,
validation_steps = 660//batch_size)

def plot_learning_curve(history):
    plt.figure(figsize=(16, 8))
    plt.subplot(1,3,1)
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch No.')
    acc = "Train Accuracy:{}".format(str(round(history.history['accuracy'][-1],2)))
    val_acc = "Val Accuracy:{}".format(str(round(history.history['val_accuracy'][-1],2)))
    plt.legend([acc, val_acc], loc='upper left')
    plt.savefig('/content/drive/My Drive/Accuracy_Curve1(60).png')
    #plt.clf()
    # summarize history for loss
    plt.subplot(1,3,2)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model Loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch No.')
    loss = "Train Loss:{}".format(str(round(history.history['loss'][-1],2)))
    val_loss = "Val Loss:{}".format(str(round(history.history['val_loss'][-1],2)))
    plt.legend([loss, val_loss], loc='upper right')
    plt.savefig('/content/drive/My Drive/Loss_Curve1(60).png')

    # plt.subplot(1,3,3)
    # plt.plot(history.history['mean_IOU_gpu'])
    # plt.plot(history.history['val_mean_IOU_gpu'])
    # plt.title('Mean_IoU')
    # plt.ylabel('Mean_IoU')
    # plt.xlabel('Epoch No.')
    # plt.legend(['train', 'test'], loc='upper left')
    # plt.savefig('/content/drive/My Drive/Mean_IoU_curve.png')

model.save('my_model30.h5')

plot_learning_curve(model_info)

"""TEST

"""

import tensorflow as tf
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.layers import Dense, Conv2D, Flatten,GlobalMaxPooling2D, Dropout, MaxPooling2D,GlobalAveragePooling2D,BatchNormalization,concatenate,Input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.applications import InceptionV3
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import pandas as pd
import os
from tensorflow.keras.models import load_model
from PIL import Image
from tensorflow.keras.preprocessing import image
import numpy as np
import cv2
import itertools
import glob
from sklearn.metrics import confusion_matrix
import tensorflow as ktf

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion_matrix.png',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)
    tp = cm[0,0]
    fp = cm[0,1]
    fn = cm[1,0]
    tn = cm[1,1]
    sensitivity = (tp)/(tp+fn)
    specificity = (tn)/(tn+fp)

    print("the sensitivity",sensitivity)
    print("the specificity",specificity)

    temp1 = round(((cm[0,0])/(cm[0,0]+cm[0,1]))*100)
    temp2 = round(((cm[0,1])/(cm[0,0]+cm[0,1]))*100)
    temp3 = round(((cm[1,0])/(cm[1,0]+cm[1,1]))*100)
    temp4 = round(((cm[1,1])/(cm[1,0]+cm[1,1]))*100)

    print(temp1,temp2,temp3,temp4)
    cm[0,0] = temp1
    cm[0,1] = temp2
    cm[1,0] = temp3
    cm[1,1] = temp4
    print(cm)


    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    filename = "{}.png".format(title)
    plt.savefig(filename)

model=load_model('/content/drive/My Drive/my_model30.h5')
model.summary()

f = open('incresnt_metrics2.txt','w')
for m in glob.glob('/content/drive/My Drive/my_model30.h5'):
    f.write(m)
    f.write('\n')
    model=load_model('/content/drive/My Drive/my_model30.h5')
    test_datagen = ImageDataGenerator(rescale = 1./255)
    test_set = test_datagen.flow_from_directory('/content/drive/My Drive/test/test',
    target_size = (256,256),
    batch_size = 1,
    class_mode = 'binary')
    eval_steps = test_set.n//test_set.batch_size
    print(eval_steps)
    count = 0
    true_count = 0
    false_count = 0
    for i in range(0,eval_steps):
        count = count+1
        x, y = next(iter(test_set))

       # x,y = test_set.next()
        true = (int)(round(y[0]))
        predict = (model.predict(x))
        predict = (int)(round(predict[0][0]))
        if(true==predict):
            true_count = true_count+1
        else:
            false_count = false_count+1
    result= "count ={0} , true_count={1} and false_count ={2}".format(count,true_count,false_count)
    f.write(result)
    f.write('\n')
    print(count,true_count,false_count)

f = open('incresnt_metrics.txt','w')
true_values = []
predict_values = []
for m in glob.glob('/content/drive/My Drive/my_model30.h5'):
    f.write(m)
    f.write('\n')
    model=load_model(m)
    test_datagen = ImageDataGenerator(rescale = 1./255)
    test_set = test_datagen.flow_from_directory('/content/drive/My Drive/test/test',
    target_size = (256,256),
    batch_size = 1,
    class_mode = 'binary')
    eval_steps = test_set.n//test_set.batch_size
    print(eval_steps)
    count = 0
    true_count = 0
    false_count = 0
    for i in range(0,eval_steps):
        count = count+1
        x, y = next(iter(test_set))

        #x,y = test_set.next()
        true = (int)(round(y[0]))
        predict = (model.predict(x))
        predict = (int)(round(predict[0][0]))
        true_values.append(true)
        predict_values.append(predict)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

results = confusion_matrix(true_values, predict_values)

print(results)
print('Accuracy Score :',accuracy_score(true_values, predict_values))
print('Report : ')
print(classification_report(true_values, predict_values))

results = confusion_matrix(true_values, predict_values)

print(len(true_values),len(predict_values))

cm = confusion_matrix(true_values, predict_values)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(cm, classes=['Benign', 'Malignant'],title='Skin Cancer')



